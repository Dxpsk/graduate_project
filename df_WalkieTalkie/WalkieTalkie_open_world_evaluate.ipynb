{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "from torch import nn \n",
    "import numpy as np\n",
    "import wandb\n",
    "import tqdm\n",
    "import d2l.torch as d2l\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(classes):\n",
    "    filter_num = ['None',32,64,128,256]\n",
    "    kernel_size = ['None',9,9,9,9]\n",
    "    conv_stride_size = ['None',1,1,1,1]\n",
    "    pool_stride_size = ['None',4,4,4,4]\n",
    "    pool_size = ['None',8,8,8,8]\n",
    "    net = nn.Sequential(\n",
    "        nn.Conv1d(in_channels=1, out_channels=filter_num[1], kernel_size=kernel_size[1], stride=conv_stride_size[1], padding=4),\n",
    "        nn.BatchNorm1d(num_features=32),\n",
    "        nn.ELU(alpha=1.0),\n",
    "        nn.Conv1d(in_channels=32, out_channels=filter_num[1], kernel_size=kernel_size[1], stride=conv_stride_size[1], padding=4),\n",
    "        nn.BatchNorm1d(num_features=32),\n",
    "        nn.ELU(alpha=1.0),\n",
    "        nn.MaxPool1d(kernel_size=pool_size[1], stride=pool_stride_size[1], padding=2),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Conv1d(in_channels=32, out_channels=filter_num[2], kernel_size=kernel_size[2], stride=conv_stride_size[2], padding=4),\n",
    "        nn.BatchNorm1d(num_features=64),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv1d(in_channels=64, out_channels=filter_num[2], kernel_size=kernel_size[2], stride=conv_stride_size[2], padding=4),\n",
    "        nn.BatchNorm1d(num_features=64),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(kernel_size=pool_size[2], stride=pool_stride_size[2], padding=3),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Conv1d(in_channels=64, out_channels=filter_num[3], kernel_size=kernel_size[3], stride=conv_stride_size[3], padding=4),\n",
    "        nn.BatchNorm1d(num_features=128),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv1d(in_channels=128, out_channels=filter_num[3], kernel_size=kernel_size[3], stride=conv_stride_size[3], padding=4),\n",
    "        nn.BatchNorm1d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(kernel_size=pool_size[3], stride=pool_stride_size[3], padding=4),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Conv1d(in_channels=128, out_channels=filter_num[4], kernel_size=kernel_size[4], stride=conv_stride_size[4], padding=4),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv1d(in_channels=256, out_channels=filter_num[4], kernel_size=kernel_size[4], stride=conv_stride_size[4], padding=4),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(kernel_size=pool_size[4], stride=pool_stride_size[4], padding=4),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Flatten(start_dim=-2),\n",
    "        nn.Linear(256 * 20, 512),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.7),\n",
    "        nn.Linear(512, 512),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(512, classes)\n",
    "    )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n",
      "Use the model from:  /home/xjj/projects/graduate_project/df_WalkieTalkie/WalkieTalkie_ow_model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv1d(1, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ELU(alpha=1.0)\n",
       "  (3): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ELU(alpha=1.0)\n",
       "  (6): MaxPool1d(kernel_size=8, stride=4, padding=2, dilation=1, ceil_mode=False)\n",
       "  (7): Dropout(p=0.1, inplace=False)\n",
       "  (8): Conv1d(32, 64, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU()\n",
       "  (11): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (12): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): ReLU()\n",
       "  (14): MaxPool1d(kernel_size=8, stride=4, padding=3, dilation=1, ceil_mode=False)\n",
       "  (15): Dropout(p=0.1, inplace=False)\n",
       "  (16): Conv1d(64, 128, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (17): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (18): ReLU()\n",
       "  (19): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (20): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (21): ReLU()\n",
       "  (22): MaxPool1d(kernel_size=8, stride=4, padding=4, dilation=1, ceil_mode=False)\n",
       "  (23): Dropout(p=0.1, inplace=False)\n",
       "  (24): Conv1d(128, 256, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (25): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (26): ReLU()\n",
       "  (27): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (28): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (29): ReLU()\n",
       "  (30): MaxPool1d(kernel_size=8, stride=4, padding=4, dilation=1, ceil_mode=False)\n",
       "  (31): Dropout(p=0.1, inplace=False)\n",
       "  (32): Flatten(start_dim=-2, end_dim=-1)\n",
       "  (33): Linear(in_features=5120, out_features=512, bias=True)\n",
       "  (34): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (35): ReLU()\n",
       "  (36): Dropout(p=0.7, inplace=False)\n",
       "  (37): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (38): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (39): ReLU()\n",
       "  (40): Dropout(p=0.5, inplace=False)\n",
       "  (41): Linear(in_features=512, out_features=101, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(f'cuda:{6}')\n",
    "net = make_model(101)\n",
    "state_dict = torch.load('/home/xjj/projects/graduate_project/df_WalkieTalkie/WalkieTalkie_ow_model')\n",
    "print (\"Model loaded!\")\n",
    "print (\"Use the model from: \", '/home/xjj/projects/graduate_project/df_WalkieTalkie/WalkieTalkie_ow_model')\n",
    "net.load_state_dict(state_dict)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadDataWalkieTalkieOW_Evaluation():\n",
    "\n",
    "    print (\"Loading WWalkieTalkie dataset for open-world scenario for evaluation\")\n",
    "    # Point to the directory storing data\n",
    "    dataset_dir = '/data/Deep_fingerprint/walkie_talkie/open_world/'\n",
    "\n",
    "    # X represents a sequence of traffic directions\n",
    "    # y represents a sequence of corresponding label (website's label)\n",
    "\n",
    "    # Load training data\n",
    "    with open(dataset_dir + 'X_test_Mon_WalkieTalkie.pkl', 'rb') as handle:\n",
    "        X_test_Mon = pickle.load(handle, encoding='latin1')\n",
    "    with open(dataset_dir + 'y_test_Mon_WalkieTalkie.pkl', 'rb') as handle:\n",
    "        y_test_Mon = pickle.load(handle, encoding='latin1')\n",
    "    with open(dataset_dir + 'X_test_Unmon_WalkieTalkie.pkl', 'rb') as handle:\n",
    "        X_test_Unmon = pickle.load(handle, encoding='latin1')\n",
    "    with open(dataset_dir + 'y_test_Unmon_WalkieTalkie.pkl', 'rb') as handle:\n",
    "        y_test_Unmon = pickle.load(handle, encoding='latin1')\n",
    "\n",
    "    X_test_Mon = np.array(X_test_Mon)\n",
    "    y_test_Mon = np.array(y_test_Mon)\n",
    "    X_test_Unmon = np.array(X_test_Unmon)\n",
    "    y_test_Unmon = np.array(y_test_Unmon)\n",
    "    \n",
    "    X_test_Mon = X_test_Mon[:, np.newaxis, :]\n",
    "    X_test_Unmon = X_test_Unmon[:, np.newaxis, :]\n",
    "\n",
    "    X_test_Mon = torch.FloatTensor(X_test_Mon)\n",
    "    y_test_Mon = torch.FloatTensor(y_test_Mon)\n",
    "    X_test_Unmon = torch.FloatTensor(X_test_Unmon)\n",
    "    y_test_Unmon = torch.FloatTensor(y_test_Unmon)\n",
    "\n",
    "    return X_test_Mon, y_test_Mon, X_test_Unmon, y_test_Unmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, model):\n",
    "    model.eval()\n",
    "    X_test_Mon = dataset['X_test_Mon']\n",
    "    X_test_Unmon = dataset['X_test_Unmon']\n",
    "    print (\"Total testing data \", len(X_test_Mon) + len(X_test_Unmon))\n",
    "     # 创建 DataLoader\n",
    "    loader_Mon = torch.utils.data.DataLoader(X_test_Mon, batch_size=256, shuffle=False)\n",
    "    loader_Unmon = torch.utils.data.DataLoader(X_test_Unmon, batch_size=256, shuffle=False)\n",
    "\n",
    "    # 分批次处理输入数据，并将结果合并\n",
    "    with torch.no_grad():\n",
    "        result_Mon = torch.cat([F.softmax(model(x.to(device)), dim=1) for x in loader_Mon], dim=0)\n",
    "        result_Unmon = torch.cat([F.softmax(model(x.to(device)), dim=1) for x in loader_Unmon], dim=0)\n",
    "    \n",
    "    return result_Mon, result_Unmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(threshold_val, mon_label, unmon_label, result_mon, result_unmon, log_file):\n",
    "    # Calculate the number of misclassifications\n",
    "    mon_label = mon_label.cpu().numpy()\n",
    "    unmon_label = unmon_label.cpu().numpy()\n",
    "    result_mon = result_mon.cpu().numpy()\n",
    "    result_unmon = result_unmon.cpu().numpy()\n",
    "\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    \n",
    "    # 要求预测类别正确\n",
    "    mon_correct = (result_mon.argmax(axis=1)==mon_label).sum()\n",
    "    unmon_correct = (result_unmon.argmax(axis=1)==unmon_label).sum()\n",
    "    test_acc = (mon_correct + unmon_correct)/(len(mon_label)+len(unmon_label))    \n",
    "    \n",
    "    \n",
    "    #置信度是对预测为正例的概率的要求\n",
    "    for i in range(len(result_mon)):\n",
    "        sm_vector = result_mon[i]\n",
    "        predicted_class = np.argmax(sm_vector)\n",
    "        max_prob = max(sm_vector)\n",
    "\n",
    "        if predicted_class in mon_label: # predicted as Monitored\n",
    "            if max_prob >= threshold_val: # predicted as Monitored and actual site is Monitored\n",
    "                TP = TP + 1\n",
    "            else: # predicted as Unmonitored and actual site is Monitored\n",
    "                FN = FN + 1\n",
    "        elif predicted_class in unmon_label: # predicted as Unmonitored and actual site is Monitored\n",
    "            FN = FN + 1\n",
    "\n",
    "    # ==============================================================\n",
    "    # Test with Unmonitored testing instances\n",
    "    # evaluation\n",
    "    for i in range(len(result_unmon)):\n",
    "        sm_vector = result_unmon[i]\n",
    "        predicted_class = np.argmax(sm_vector)\n",
    "        max_prob = max(sm_vector)\n",
    "\n",
    "        if predicted_class in mon_label: # predicted as Monitored\n",
    "            if max_prob >= threshold_val: # predicted as Monitored and actual site is Unmonitored\n",
    "                FP = FP + 1\n",
    "            else: # predicted as Unmonitored and actual site is Unmonitored\n",
    "                TN = TN + 1\n",
    "        elif predicted_class in unmon_label: # predicted as Unmonitored and actual site is Unmonitored\n",
    "            TN = TN + 1\n",
    "\n",
    "    \n",
    "    print (\"TP : \", TP)\n",
    "    print (\"FP : \", FP)\n",
    "    print (\"TN : \", TN)\n",
    "    print (\"FN : \", FN)\n",
    "    print (\"Total  : \", TP + FP + TN + FN)\n",
    "    TPR = float(TP) / (TP + FN)\n",
    "    print (\"TPR : \", TPR)\n",
    "    FPR = float(FP) / (FP + TN)\n",
    "    print (\"FPR : \",  FPR)\n",
    "    Precision = float(TP) / (TP + FP)\n",
    "    print (\"Precision : \", Precision)\n",
    "    Recall = float(TP) / (TP + FN)\n",
    "    print (\"Recall : \", Recall)\n",
    "    log_file.writelines(f\"two-*:\\nthreshold_val: {threshold_val}\\nTP: {TP}, FP: {FP}, TN: {TN}, FN: {FN}\\nTPR:{TPR}, FPR:{FPR}, Precision: {Precision}, Recall:{Recall}\\n\")\n",
    "    \n",
    "    log_file.writelines(f\"test_acc:\\nmon_correct: {mon_correct}  unmon_correct: {unmon_correct}\\nmon_num: {len(mon_label)}   unmon_num: {len(unmon_label)}\\nTest Accuracy: {test_acc}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation type:  OpenWorld_WalkieTalkie\n",
      "置信度:  [0.10874906 0.35328299 0.53072375 0.65947982 0.75290888 0.82070366\n",
      " 0.86989748 0.90559391 0.93149626 0.95029174 0.96393027 0.97382678\n",
      " 0.98100797 0.98621884 0.99      ]\n"
     ]
    }
   ],
   "source": [
    "evaluation_type = 'OpenWorld_WalkieTalkie'\n",
    "print (\"Evaluation type: \", evaluation_type)\n",
    "threshold = 1.0 - 1 / np.logspace(0.05, 2, num=15, endpoint=True)\n",
    "print('置信度: ', threshold)\n",
    "file_name = f'/home/xjj/projects/graduate_project/df_WalkieTalkie/evaluation/{evaluation_type}_two.txt'\n",
    "log_file =  open(file_name, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading WWalkieTalkie dataset for open-world scenario for evaluation\n",
      "Data loaded!\n",
      "Loading DF model ...\n",
      "The log file will be saved at  /home/xjj/projects/graduate_project/df_WalkieTalkie/evaluation/OpenWorld_WalkieTalkie_two.txt\n",
      "-- The log file will contains\n",
      "-- TP, FP, TN, FN, TPR, FPR, Precision, and Recall for each different threshold\n",
      "-- These results will be used to plot the ROC or Precision&Recall Graph\n"
     ]
    }
   ],
   "source": [
    "dataset = {}\n",
    "X_test_Mon, y_test_Mon, X_test_Unmon, y_test_Unmon = LoadDataWalkieTalkieOW_Evaluation()\n",
    "\n",
    "dataset['X_test_Mon'] = X_test_Mon\n",
    "dataset['y_test_Mon'] = y_test_Mon\n",
    "dataset['X_test_Unmon'] = X_test_Unmon\n",
    "dataset['y_test_Unmon'] = y_test_Unmon\n",
    "\n",
    "print (\"Data loaded!\")\n",
    "print (\"Loading DF model ...\")\n",
    "print (\"The log file will be saved at \", file_name)\n",
    "print (\"-- The log file will contains\")\n",
    "print (\"-- TP, FP, TN, FN, TPR, FPR, Precision, and Recall for each different threshold\")\n",
    "print (\"-- These results will be used to plot the ROC or Precision&Recall Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(99.) tensor(0.)\n",
      "tensor(100.) tensor(100.)\n"
     ]
    }
   ],
   "source": [
    "print(y_test_Mon.max(), y_test_Mon.min())     #94 0\n",
    "print(y_test_Unmon.max(), y_test_Unmon.min())    #95 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total testing data  29000\n",
      "torch.Size([9000, 101]) torch.Size([20000, 101])\n"
     ]
    }
   ],
   "source": [
    "result_Mon, result_Unmon = predict(dataset, net)\n",
    "print(result_Mon.shape, result_Unmon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP :  8279\n",
      "FP :  15332\n",
      "TN :  4668\n",
      "FN :  721\n",
      "Total  :  29000\n",
      "TPR :  0.9198888888888889\n",
      "FPR :  0.7666\n",
      "Precision :  0.3506416500783533\n",
      "Recall :  0.9198888888888889\n",
      "TP :  7766\n",
      "FP :  14281\n",
      "TN :  5719\n",
      "FN :  1234\n",
      "Total  :  29000\n",
      "TPR :  0.8628888888888889\n",
      "FPR :  0.71405\n",
      "Precision :  0.35224747131128953\n",
      "Recall :  0.8628888888888889\n",
      "TP :  6668\n",
      "FP :  12117\n",
      "TN :  7883\n",
      "FN :  2332\n",
      "Total  :  29000\n",
      "TPR :  0.7408888888888889\n",
      "FPR :  0.60585\n",
      "Precision :  0.3549640670747937\n",
      "Recall :  0.7408888888888889\n",
      "TP :  5823\n",
      "FP :  10555\n",
      "TN :  9445\n",
      "FN :  3177\n",
      "Total  :  29000\n",
      "TPR :  0.647\n",
      "FPR :  0.52775\n",
      "Precision :  0.3555379167175479\n",
      "Recall :  0.647\n",
      "TP :  5197\n",
      "FP :  9480\n",
      "TN :  10520\n",
      "FN :  3803\n",
      "Total  :  29000\n",
      "TPR :  0.5774444444444444\n",
      "FPR :  0.474\n",
      "Precision :  0.3540914355794781\n",
      "Recall :  0.5774444444444444\n",
      "TP :  4635\n",
      "FP :  8578\n",
      "TN :  11422\n",
      "FN :  4365\n",
      "Total  :  29000\n",
      "TPR :  0.515\n",
      "FPR :  0.4289\n",
      "Precision :  0.35079088776205253\n",
      "Recall :  0.515\n",
      "TP :  4104\n",
      "FP :  7744\n",
      "TN :  12256\n",
      "FN :  4896\n",
      "Total  :  29000\n",
      "TPR :  0.456\n",
      "FPR :  0.3872\n",
      "Precision :  0.3463875759621877\n",
      "Recall :  0.456\n",
      "TP :  3635\n",
      "FP :  6976\n",
      "TN :  13024\n",
      "FN :  5365\n",
      "Total  :  29000\n",
      "TPR :  0.4038888888888889\n",
      "FPR :  0.3488\n",
      "Precision :  0.34256903213646217\n",
      "Recall :  0.4038888888888889\n",
      "TP :  3180\n",
      "FP :  6203\n",
      "TN :  13797\n",
      "FN :  5820\n",
      "Total  :  29000\n",
      "TPR :  0.35333333333333333\n",
      "FPR :  0.31015\n",
      "Precision :  0.33891079612064373\n",
      "Recall :  0.35333333333333333\n",
      "TP :  2730\n",
      "FP :  5420\n",
      "TN :  14580\n",
      "FN :  6270\n",
      "Total  :  29000\n",
      "TPR :  0.30333333333333334\n",
      "FPR :  0.271\n",
      "Precision :  0.33496932515337424\n",
      "Recall :  0.30333333333333334\n",
      "TP :  2325\n",
      "FP :  4667\n",
      "TN :  15333\n",
      "FN :  6675\n",
      "Total  :  29000\n",
      "TPR :  0.25833333333333336\n",
      "FPR :  0.23335\n",
      "Precision :  0.3325228832951945\n",
      "Recall :  0.25833333333333336\n",
      "TP :  1939\n",
      "FP :  3913\n",
      "TN :  16087\n",
      "FN :  7061\n",
      "Total  :  29000\n",
      "TPR :  0.21544444444444444\n",
      "FPR :  0.19565\n",
      "Precision :  0.33133971291866027\n",
      "Recall :  0.21544444444444444\n",
      "TP :  1568\n",
      "FP :  3207\n",
      "TN :  16793\n",
      "FN :  7432\n",
      "Total  :  29000\n",
      "TPR :  0.17422222222222222\n",
      "FPR :  0.16035\n",
      "Precision :  0.32837696335078537\n",
      "Recall :  0.17422222222222222\n",
      "TP :  1239\n",
      "FP :  2600\n",
      "TN :  17400\n",
      "FN :  7761\n",
      "Total  :  29000\n",
      "TPR :  0.13766666666666666\n",
      "FPR :  0.13\n",
      "Precision :  0.32274029695233136\n",
      "Recall :  0.13766666666666666\n",
      "TP :  951\n",
      "FP :  1993\n",
      "TN :  18007\n",
      "FN :  8049\n",
      "Total  :  29000\n",
      "TPR :  0.10566666666666667\n",
      "FPR :  0.09965\n",
      "Precision :  0.32302989130434784\n",
      "Recall :  0.10566666666666667\n"
     ]
    }
   ],
   "source": [
    "for th in threshold:\n",
    "    evaluate(th, y_test_Mon, y_test_Unmon, result_Mon, result_Unmon, log_file)\n",
    "log_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
