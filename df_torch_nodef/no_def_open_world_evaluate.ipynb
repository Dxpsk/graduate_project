{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "from torch import nn \n",
    "import numpy as np\n",
    "import wandb\n",
    "import tqdm\n",
    "import d2l.torch as d2l\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(classes):\n",
    "    filter_num = ['None',32,64,128,256]\n",
    "    kernel_size = ['None',9,9,9,9]\n",
    "    conv_stride_size = ['None',1,1,1,1]\n",
    "    pool_stride_size = ['None',4,4,4,4]\n",
    "    pool_size = ['None',8,8,8,8]\n",
    "    net = nn.Sequential(\n",
    "        nn.Conv1d(in_channels=1, out_channels=filter_num[1], kernel_size=kernel_size[1], stride=conv_stride_size[1], padding=4),\n",
    "        nn.BatchNorm1d(num_features=32),\n",
    "        nn.ELU(alpha=1.0),\n",
    "        nn.Conv1d(in_channels=32, out_channels=filter_num[1], kernel_size=kernel_size[1], stride=conv_stride_size[1], padding=4),\n",
    "        nn.BatchNorm1d(num_features=32),\n",
    "        nn.ELU(alpha=1.0),\n",
    "        nn.MaxPool1d(kernel_size=pool_size[1], stride=pool_stride_size[1], padding=2),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Conv1d(in_channels=32, out_channels=filter_num[2], kernel_size=kernel_size[2], stride=conv_stride_size[2], padding=4),\n",
    "        nn.BatchNorm1d(num_features=64),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv1d(in_channels=64, out_channels=filter_num[2], kernel_size=kernel_size[2], stride=conv_stride_size[2], padding=4),\n",
    "        nn.BatchNorm1d(num_features=64),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(kernel_size=pool_size[2], stride=pool_stride_size[2], padding=3),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Conv1d(in_channels=64, out_channels=filter_num[3], kernel_size=kernel_size[3], stride=conv_stride_size[3], padding=4),\n",
    "        nn.BatchNorm1d(num_features=128),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv1d(in_channels=128, out_channels=filter_num[3], kernel_size=kernel_size[3], stride=conv_stride_size[3], padding=4),\n",
    "        nn.BatchNorm1d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(kernel_size=pool_size[3], stride=pool_stride_size[3], padding=4),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Conv1d(in_channels=128, out_channels=filter_num[4], kernel_size=kernel_size[4], stride=conv_stride_size[4], padding=4),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv1d(in_channels=256, out_channels=filter_num[4], kernel_size=kernel_size[4], stride=conv_stride_size[4], padding=4),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(kernel_size=pool_size[4], stride=pool_stride_size[4], padding=4),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Flatten(start_dim=-2),\n",
    "        nn.Linear(256 * 20, 512),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.7),\n",
    "        nn.Linear(512, 512),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(512, classes)\n",
    "    )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n",
      "Use the model from:  /home/xjj/projects/graduate_project/df_torch_nodef/no_def_ow_model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv1d(1, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ELU(alpha=1.0)\n",
       "  (3): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ELU(alpha=1.0)\n",
       "  (6): MaxPool1d(kernel_size=8, stride=4, padding=2, dilation=1, ceil_mode=False)\n",
       "  (7): Dropout(p=0.1, inplace=False)\n",
       "  (8): Conv1d(32, 64, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU()\n",
       "  (11): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (12): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): ReLU()\n",
       "  (14): MaxPool1d(kernel_size=8, stride=4, padding=3, dilation=1, ceil_mode=False)\n",
       "  (15): Dropout(p=0.1, inplace=False)\n",
       "  (16): Conv1d(64, 128, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (17): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (18): ReLU()\n",
       "  (19): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (20): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (21): ReLU()\n",
       "  (22): MaxPool1d(kernel_size=8, stride=4, padding=4, dilation=1, ceil_mode=False)\n",
       "  (23): Dropout(p=0.1, inplace=False)\n",
       "  (24): Conv1d(128, 256, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (25): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (26): ReLU()\n",
       "  (27): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (28): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (29): ReLU()\n",
       "  (30): MaxPool1d(kernel_size=8, stride=4, padding=4, dilation=1, ceil_mode=False)\n",
       "  (31): Dropout(p=0.1, inplace=False)\n",
       "  (32): Flatten(start_dim=-2, end_dim=-1)\n",
       "  (33): Linear(in_features=5120, out_features=512, bias=True)\n",
       "  (34): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (35): ReLU()\n",
       "  (36): Dropout(p=0.7, inplace=False)\n",
       "  (37): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (38): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (39): ReLU()\n",
       "  (40): Dropout(p=0.5, inplace=False)\n",
       "  (41): Linear(in_features=512, out_features=96, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(f'cuda:{0}')\n",
    "net = make_model(96)\n",
    "state_dict = torch.load('/home/xjj/projects/graduate_project/df_torch_nodef/no_def_ow_model')\n",
    "print (\"Model loaded!\")\n",
    "print (\"Use the model from: \", '/home/xjj/projects/graduate_project/df_torch_nodef/no_def_ow_model')\n",
    "net.load_state_dict(state_dict)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadDataNoDefOW_Evaluation():\n",
    "\n",
    "    print (\"Loading non-defended dataset for open-world scenario for evaluation\")\n",
    "    # Point to the directory storing data\n",
    "    dataset_dir = '/data/Deep_fingerprint/no_def/open_world/'\n",
    "\n",
    "    # X represents a sequence of traffic directions\n",
    "    # y represents a sequence of corresponding label (website's label)\n",
    "\n",
    "    # Load training data\n",
    "    with open(dataset_dir + 'X_test_Mon_NoDef.pkl', 'rb') as handle:\n",
    "        X_test_Mon = pickle.load(handle, encoding='latin1')\n",
    "    with open(dataset_dir + 'y_test_Mon_NoDef.pkl', 'rb') as handle:\n",
    "        y_test_Mon = pickle.load(handle, encoding='latin1')\n",
    "    with open(dataset_dir + 'X_test_Unmon_NoDef.pkl', 'rb') as handle:\n",
    "        X_test_Unmon = pickle.load(handle, encoding='latin1')\n",
    "    with open(dataset_dir + 'y_test_Unmon_NoDef.pkl', 'rb') as handle:\n",
    "        y_test_Unmon = pickle.load(handle, encoding='latin1')\n",
    "\n",
    "    X_test_Mon = np.array(X_test_Mon)\n",
    "    y_test_Mon = np.array(y_test_Mon)\n",
    "    X_test_Unmon = np.array(X_test_Unmon)\n",
    "    y_test_Unmon = np.array(y_test_Unmon)\n",
    "    \n",
    "    X_test_Mon = X_test_Mon[:, np.newaxis, :]\n",
    "    X_test_Unmon = X_test_Unmon[:, np.newaxis, :]\n",
    "\n",
    "    X_test_Mon = torch.FloatTensor(X_test_Mon)\n",
    "    y_test_Mon = torch.FloatTensor(y_test_Mon)\n",
    "    X_test_Unmon = torch.FloatTensor(X_test_Unmon)\n",
    "    y_test_Unmon = torch.FloatTensor(y_test_Unmon)\n",
    "\n",
    "    return X_test_Mon, y_test_Mon, X_test_Unmon, y_test_Unmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, model):\n",
    "    model.eval()\n",
    "    X_test_Mon = dataset['X_test_Mon']\n",
    "    X_test_Unmon = dataset['X_test_Unmon']\n",
    "    print (\"Total testing data \", len(X_test_Mon) + len(X_test_Unmon))\n",
    "     # 创建 DataLoader\n",
    "    loader_Mon = torch.utils.data.DataLoader(X_test_Mon, batch_size=256, shuffle=False)\n",
    "    loader_Unmon = torch.utils.data.DataLoader(X_test_Unmon, batch_size=256, shuffle=False)\n",
    "\n",
    "    # 分批次处理输入数据，并将结果合并\n",
    "    with torch.no_grad():\n",
    "        result_Mon = torch.cat([F.softmax(model(x.to(device)), dim=1) for x in loader_Mon], dim=0)\n",
    "        result_Unmon = torch.cat([F.softmax(model(x.to(device)), dim=1) for x in loader_Unmon], dim=0)\n",
    "    \n",
    "    return result_Mon, result_Unmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(threshold_val, mon_label, unmon_label, result_mon, result_unmon, log_file):\n",
    "    # Calculate the number of misclassifications\n",
    "    mon_label = mon_label.cpu().numpy()\n",
    "    unmon_label = unmon_label.cpu().numpy()\n",
    "    result_mon = result_mon.cpu().numpy()\n",
    "    result_unmon = result_unmon.cpu().numpy()\n",
    "\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    \n",
    "    # 要求预测类别正确\n",
    "    mon_correct = (result_mon.argmax(axis=1)==mon_label).sum()\n",
    "    unmon_correct = (result_unmon.argmax(axis=1)==unmon_label).sum()\n",
    "    test_acc = (mon_correct + unmon_correct)/(len(mon_label)+len(unmon_label))    \n",
    "    \n",
    "    \n",
    "    #置信度是对预测为正例的概率的要求\n",
    "    for i in range(len(result_mon)):\n",
    "        sm_vector = result_mon[i]\n",
    "        predicted_class = np.argmax(sm_vector)\n",
    "        max_prob = max(sm_vector)\n",
    "\n",
    "        if predicted_class in mon_label: # predicted as Monitored\n",
    "            if max_prob >= threshold_val: # predicted as Monitored and actual site is Monitored\n",
    "                TP = TP + 1\n",
    "            else: # predicted as Unmonitored and actual site is Monitored\n",
    "                FN = FN + 1\n",
    "        elif predicted_class in unmon_label: # predicted as Unmonitored and actual site is Monitored\n",
    "            FN = FN + 1\n",
    "\n",
    "    # ==============================================================\n",
    "    # Test with Unmonitored testing instances\n",
    "    # evaluation\n",
    "    for i in range(len(result_unmon)):\n",
    "        sm_vector = result_unmon[i]\n",
    "        predicted_class = np.argmax(sm_vector)\n",
    "        max_prob = max(sm_vector)\n",
    "\n",
    "        if predicted_class in mon_label: # predicted as Monitored\n",
    "            if max_prob >= threshold_val: # predicted as Monitored and actual site is Unmonitored\n",
    "                FP = FP + 1\n",
    "            else: # predicted as Unmonitored and actual site is Unmonitored\n",
    "                TN = TN + 1\n",
    "        elif predicted_class in unmon_label: # predicted as Unmonitored and actual site is Unmonitored\n",
    "            TN = TN + 1\n",
    "\n",
    "    \n",
    "    print (\"TP : \", TP)\n",
    "    print (\"FP : \", FP)\n",
    "    print (\"TN : \", TN)\n",
    "    print (\"FN : \", FN)\n",
    "    print (\"Total  : \", TP + FP + TN + FN)\n",
    "    TPR = float(TP) / (TP + FN)\n",
    "    print (\"TPR : \", TPR)\n",
    "    FPR = float(FP) / (FP + TN)\n",
    "    print (\"FPR : \",  FPR)\n",
    "    Precision = float(TP) / (TP + FP)\n",
    "    print (\"Precision : \", Precision)\n",
    "    Recall = float(TP) / (TP + FN)\n",
    "    print (\"Recall : \", Recall)\n",
    "    log_file.writelines(f\"two-*:\\nthreshold_val: {threshold_val}\\nTP: {TP}, FP: {FP}, TN: {TN}, FN: {FN}\\nTPR:{TPR}, FPR:{FPR}, Precision: {Precision}, Recall:{Recall}\\n\")\n",
    "    \n",
    "    log_file.writelines(f\"test_acc:\\nmon_correct: {mon_correct}  unmon_correct: {unmon_correct}\\nmon_num: {len(mon_label)}   unmon_num: {len(unmon_label)}\\nTest Accuracy: {test_acc}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation type:  OpenWorld_NoDef\n",
      "置信度:  [0.10874906 0.35328299 0.53072375 0.65947982 0.75290888 0.82070366\n",
      " 0.86989748 0.90559391 0.93149626 0.95029174 0.96393027 0.97382678\n",
      " 0.98100797 0.98621884 0.99      ]\n"
     ]
    }
   ],
   "source": [
    "evaluation_type = 'OpenWorld_NoDef'\n",
    "print (\"Evaluation type: \", evaluation_type)\n",
    "threshold = 1.0 - 1 / np.logspace(0.05, 2, num=15, endpoint=True)\n",
    "print('置信度: ', threshold)\n",
    "file_name = f'/home/xjj/projects/graduate_project/df_torch_nodef/evaluation/{evaluation_type}_two.txt'\n",
    "log_file =  open(file_name, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading non-defended dataset for open-world scenario for evaluation\n",
      "Data loaded!\n",
      "Loading DF model ...\n",
      "The log file will be saved at  /home/xjj/projects/graduate_project/df_torch_nodef/evaluation/OpenWorld_NoDef_two.txt\n",
      "-- The log file will contains\n",
      "-- TP, FP, TN, FN, TPR, FPR, Precision, and Recall for each different threshold\n",
      "-- These results will be used to plot the ROC or Precision&Recall Graph\n"
     ]
    }
   ],
   "source": [
    "dataset = {}\n",
    "X_test_Mon, y_test_Mon, X_test_Unmon, y_test_Unmon = LoadDataNoDefOW_Evaluation()\n",
    "\n",
    "dataset['X_test_Mon'] = X_test_Mon\n",
    "dataset['y_test_Mon'] = y_test_Mon\n",
    "dataset['X_test_Unmon'] = X_test_Unmon\n",
    "dataset['y_test_Unmon'] = y_test_Unmon\n",
    "\n",
    "print (\"Data loaded!\")\n",
    "print (\"Loading DF model ...\")\n",
    "print (\"The log file will be saved at \", file_name)\n",
    "print (\"-- The log file will contains\")\n",
    "print (\"-- TP, FP, TN, FN, TPR, FPR, Precision, and Recall for each different threshold\")\n",
    "print (\"-- These results will be used to plot the ROC or Precision&Recall Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(94.) tensor(0.)\n",
      "tensor(95.) tensor(95.)\n"
     ]
    }
   ],
   "source": [
    "print(y_test_Mon.max(), y_test_Mon.min())     #94 0\n",
    "print(y_test_Unmon.max(), y_test_Unmon.min())    #95 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total testing data  29500\n",
      "torch.Size([9500, 96]) torch.Size([20000, 96])\n"
     ]
    }
   ],
   "source": [
    "result_Mon, result_Unmon = predict(dataset, net)\n",
    "print(result_Mon.shape, result_Unmon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP :  9396\n",
      "FP :  881\n",
      "TN :  19119\n",
      "FN :  104\n",
      "Total  :  29500\n",
      "TPR :  0.9890526315789474\n",
      "FPR :  0.04405\n",
      "Precision :  0.9142745937530408\n",
      "Recall :  0.9890526315789474\n",
      "TP :  9347\n",
      "FP :  744\n",
      "TN :  19256\n",
      "FN :  153\n",
      "Total  :  29500\n",
      "TPR :  0.9838947368421053\n",
      "FPR :  0.0372\n",
      "Precision :  0.9262709344960857\n",
      "Recall :  0.9838947368421053\n",
      "TP :  9304\n",
      "FP :  574\n",
      "TN :  19426\n",
      "FN :  196\n",
      "Total  :  29500\n",
      "TPR :  0.9793684210526316\n",
      "FPR :  0.0287\n",
      "Precision :  0.9418910710670176\n",
      "Recall :  0.9793684210526316\n",
      "TP :  9260\n",
      "FP :  454\n",
      "TN :  19546\n",
      "FN :  240\n",
      "Total  :  29500\n",
      "TPR :  0.9747368421052631\n",
      "FPR :  0.0227\n",
      "Precision :  0.9532633312744493\n",
      "Recall :  0.9747368421052631\n",
      "TP :  9226\n",
      "FP :  371\n",
      "TN :  19629\n",
      "FN :  274\n",
      "Total  :  29500\n",
      "TPR :  0.9711578947368421\n",
      "FPR :  0.01855\n",
      "Precision :  0.9613420860685631\n",
      "Recall :  0.9711578947368421\n",
      "TP :  9201\n",
      "FP :  317\n",
      "TN :  19683\n",
      "FN :  299\n",
      "Total  :  29500\n",
      "TPR :  0.9685263157894737\n",
      "FPR :  0.01585\n",
      "Precision :  0.9666946837570918\n",
      "Recall :  0.9685263157894737\n",
      "TP :  9179\n",
      "FP :  257\n",
      "TN :  19743\n",
      "FN :  321\n",
      "Total  :  29500\n",
      "TPR :  0.9662105263157895\n",
      "FPR :  0.01285\n",
      "Precision :  0.9727638830012717\n",
      "Recall :  0.9662105263157895\n",
      "TP :  9157\n",
      "FP :  222\n",
      "TN :  19778\n",
      "FN :  343\n",
      "Total  :  29500\n",
      "TPR :  0.9638947368421052\n",
      "FPR :  0.0111\n",
      "Precision :  0.9763300991576928\n",
      "Recall :  0.9638947368421052\n",
      "TP :  9127\n",
      "FP :  196\n",
      "TN :  19804\n",
      "FN :  373\n",
      "Total  :  29500\n",
      "TPR :  0.9607368421052631\n",
      "FPR :  0.0098\n",
      "Precision :  0.9789767242303979\n",
      "Recall :  0.9607368421052631\n",
      "TP :  9105\n",
      "FP :  174\n",
      "TN :  19826\n",
      "FN :  395\n",
      "Total  :  29500\n",
      "TPR :  0.958421052631579\n",
      "FPR :  0.0087\n",
      "Precision :  0.9812479793081151\n",
      "Recall :  0.958421052631579\n",
      "TP :  9082\n",
      "FP :  156\n",
      "TN :  19844\n",
      "FN :  418\n",
      "Total  :  29500\n",
      "TPR :  0.956\n",
      "FPR :  0.0078\n",
      "Precision :  0.9831132279714224\n",
      "Recall :  0.956\n",
      "TP :  9047\n",
      "FP :  138\n",
      "TN :  19862\n",
      "FN :  453\n",
      "Total  :  29500\n",
      "TPR :  0.9523157894736842\n",
      "FPR :  0.0069\n",
      "Precision :  0.9849755035383778\n",
      "Recall :  0.9523157894736842\n",
      "TP :  9030\n",
      "FP :  113\n",
      "TN :  19887\n",
      "FN :  470\n",
      "Total  :  29500\n",
      "TPR :  0.9505263157894737\n",
      "FPR :  0.00565\n",
      "Precision :  0.987640818112217\n",
      "Recall :  0.9505263157894737\n",
      "TP :  9003\n",
      "FP :  105\n",
      "TN :  19895\n",
      "FN :  497\n",
      "Total  :  29500\n",
      "TPR :  0.9476842105263158\n",
      "FPR :  0.00525\n",
      "Precision :  0.988471673254282\n",
      "Recall :  0.9476842105263158\n",
      "TP :  8976\n",
      "FP :  93\n",
      "TN :  19907\n",
      "FN :  524\n",
      "Total  :  29500\n",
      "TPR :  0.9448421052631579\n",
      "FPR :  0.00465\n",
      "Precision :  0.9897452861395964\n",
      "Recall :  0.9448421052631579\n"
     ]
    }
   ],
   "source": [
    "for th in threshold:\n",
    "    evaluate(th, y_test_Mon, y_test_Unmon, result_Mon, result_Unmon, log_file)\n",
    "log_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
