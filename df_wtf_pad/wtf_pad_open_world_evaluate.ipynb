{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "from torch import nn \n",
    "import numpy as np\n",
    "import wandb\n",
    "import tqdm\n",
    "import d2l.torch as d2l\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(classes):\n",
    "    filter_num = ['None',32,64,128,256]\n",
    "    kernel_size = ['None',9,9,9,9]\n",
    "    conv_stride_size = ['None',1,1,1,1]\n",
    "    pool_stride_size = ['None',4,4,4,4]\n",
    "    pool_size = ['None',8,8,8,8]\n",
    "    net = nn.Sequential(\n",
    "        nn.Conv1d(in_channels=1, out_channels=filter_num[1], kernel_size=kernel_size[1], stride=conv_stride_size[1], padding=4),\n",
    "        nn.BatchNorm1d(num_features=32),\n",
    "        nn.ELU(alpha=1.0),\n",
    "        nn.Conv1d(in_channels=32, out_channels=filter_num[1], kernel_size=kernel_size[1], stride=conv_stride_size[1], padding=4),\n",
    "        nn.BatchNorm1d(num_features=32),\n",
    "        nn.ELU(alpha=1.0),\n",
    "        nn.MaxPool1d(kernel_size=pool_size[1], stride=pool_stride_size[1], padding=2),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Conv1d(in_channels=32, out_channels=filter_num[2], kernel_size=kernel_size[2], stride=conv_stride_size[2], padding=4),\n",
    "        nn.BatchNorm1d(num_features=64),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv1d(in_channels=64, out_channels=filter_num[2], kernel_size=kernel_size[2], stride=conv_stride_size[2], padding=4),\n",
    "        nn.BatchNorm1d(num_features=64),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(kernel_size=pool_size[2], stride=pool_stride_size[2], padding=3),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Conv1d(in_channels=64, out_channels=filter_num[3], kernel_size=kernel_size[3], stride=conv_stride_size[3], padding=4),\n",
    "        nn.BatchNorm1d(num_features=128),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv1d(in_channels=128, out_channels=filter_num[3], kernel_size=kernel_size[3], stride=conv_stride_size[3], padding=4),\n",
    "        nn.BatchNorm1d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(kernel_size=pool_size[3], stride=pool_stride_size[3], padding=4),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Conv1d(in_channels=128, out_channels=filter_num[4], kernel_size=kernel_size[4], stride=conv_stride_size[4], padding=4),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv1d(in_channels=256, out_channels=filter_num[4], kernel_size=kernel_size[4], stride=conv_stride_size[4], padding=4),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(kernel_size=pool_size[4], stride=pool_stride_size[4], padding=4),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Flatten(start_dim=-2),\n",
    "        nn.Linear(256 * 20, 512),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.7),\n",
    "        nn.Linear(512, 512),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(512, classes)\n",
    "    )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n",
      "Use the model from:  /home/xjj/projects/graduate_project/df_wtf_pad/wtf_pad_ow_model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv1d(1, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ELU(alpha=1.0)\n",
       "  (3): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ELU(alpha=1.0)\n",
       "  (6): MaxPool1d(kernel_size=8, stride=4, padding=2, dilation=1, ceil_mode=False)\n",
       "  (7): Dropout(p=0.1, inplace=False)\n",
       "  (8): Conv1d(32, 64, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU()\n",
       "  (11): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (12): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): ReLU()\n",
       "  (14): MaxPool1d(kernel_size=8, stride=4, padding=3, dilation=1, ceil_mode=False)\n",
       "  (15): Dropout(p=0.1, inplace=False)\n",
       "  (16): Conv1d(64, 128, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (17): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (18): ReLU()\n",
       "  (19): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (20): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (21): ReLU()\n",
       "  (22): MaxPool1d(kernel_size=8, stride=4, padding=4, dilation=1, ceil_mode=False)\n",
       "  (23): Dropout(p=0.1, inplace=False)\n",
       "  (24): Conv1d(128, 256, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (25): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (26): ReLU()\n",
       "  (27): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (28): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (29): ReLU()\n",
       "  (30): MaxPool1d(kernel_size=8, stride=4, padding=4, dilation=1, ceil_mode=False)\n",
       "  (31): Dropout(p=0.1, inplace=False)\n",
       "  (32): Flatten(start_dim=-2, end_dim=-1)\n",
       "  (33): Linear(in_features=5120, out_features=512, bias=True)\n",
       "  (34): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (35): ReLU()\n",
       "  (36): Dropout(p=0.7, inplace=False)\n",
       "  (37): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (38): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (39): ReLU()\n",
       "  (40): Dropout(p=0.5, inplace=False)\n",
       "  (41): Linear(in_features=512, out_features=96, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(f'cuda:{6}')\n",
    "net = make_model(96)\n",
    "state_dict = torch.load('/home/xjj/projects/graduate_project/df_wtf_pad/wtf_pad_ow_model')\n",
    "print (\"Model loaded!\")\n",
    "print (\"Use the model from: \", '/home/xjj/projects/graduate_project/df_wtf_pad/wtf_pad_ow_model')\n",
    "net.load_state_dict(state_dict)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadDataWTFPADOW_Evaluation():\n",
    "\n",
    "    print (\"Loading WTFPAD dataset for open-world scenario for evaluation\")\n",
    "    # Point to the directory storing data\n",
    "    dataset_dir = '/data/Deep_fingerprint/wtf_pad/open_world/'\n",
    "\n",
    "    # X represents a sequence of traffic directions\n",
    "    # y represents a sequence of corresponding label (website's label)\n",
    "\n",
    "    # Load training data\n",
    "    with open(dataset_dir + 'X_test_Mon_WTFPAD.pkl', 'rb') as handle:\n",
    "        X_test_Mon = pickle.load(handle, encoding='latin1')\n",
    "    with open(dataset_dir + 'y_test_Mon_WTFPAD.pkl', 'rb') as handle:\n",
    "        y_test_Mon = pickle.load(handle, encoding='latin1')\n",
    "    with open(dataset_dir + 'X_test_Unmon_WTFPAD.pkl', 'rb') as handle:\n",
    "        X_test_Unmon = pickle.load(handle, encoding='latin1')\n",
    "    with open(dataset_dir + 'y_test_Unmon_WTFPAD.pkl', 'rb') as handle:\n",
    "        y_test_Unmon = pickle.load(handle, encoding='latin1')\n",
    "\n",
    "    X_test_Mon = np.array(X_test_Mon)\n",
    "    y_test_Mon = np.array(y_test_Mon)\n",
    "    X_test_Unmon = np.array(X_test_Unmon)\n",
    "    y_test_Unmon = np.array(y_test_Unmon)\n",
    "    \n",
    "    X_test_Mon = X_test_Mon[:, np.newaxis, :]\n",
    "    X_test_Unmon = X_test_Unmon[:, np.newaxis, :]\n",
    "\n",
    "    X_test_Mon = torch.FloatTensor(X_test_Mon)\n",
    "    y_test_Mon = torch.FloatTensor(y_test_Mon)\n",
    "    X_test_Unmon = torch.FloatTensor(X_test_Unmon)\n",
    "    y_test_Unmon = torch.FloatTensor(y_test_Unmon)\n",
    "\n",
    "    return X_test_Mon, y_test_Mon, X_test_Unmon, y_test_Unmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, model):\n",
    "    model.eval()\n",
    "    X_test_Mon = dataset['X_test_Mon']\n",
    "    X_test_Unmon = dataset['X_test_Unmon']\n",
    "    print (\"Total testing data \", len(X_test_Mon) + len(X_test_Unmon))\n",
    "     # 创建 DataLoader\n",
    "    loader_Mon = torch.utils.data.DataLoader(X_test_Mon, batch_size=256, shuffle=False)\n",
    "    loader_Unmon = torch.utils.data.DataLoader(X_test_Unmon, batch_size=256, shuffle=False)\n",
    "\n",
    "    # 分批次处理输入数据，并将结果合并\n",
    "    with torch.no_grad():\n",
    "        result_Mon = torch.cat([F.softmax(model(x.to(device)), dim=1) for x in loader_Mon], dim=0)\n",
    "        result_Unmon = torch.cat([F.softmax(model(x.to(device)), dim=1) for x in loader_Unmon], dim=0)\n",
    "    \n",
    "    return result_Mon, result_Unmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(threshold_val, mon_label, unmon_label, result_mon, result_unmon, log_file):\n",
    "    # Calculate the number of misclassifications\n",
    "    mon_label = mon_label.cpu().numpy()\n",
    "    unmon_label = unmon_label.cpu().numpy()\n",
    "    result_mon = result_mon.cpu().numpy()\n",
    "    result_unmon = result_unmon.cpu().numpy()\n",
    "\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    \n",
    "    # 要求预测类别正确\n",
    "    mon_correct = (result_mon.argmax(axis=1)==mon_label).sum()\n",
    "    unmon_correct = (result_unmon.argmax(axis=1)==unmon_label).sum()\n",
    "    test_acc = (mon_correct + unmon_correct)/(len(mon_label)+len(unmon_label))    \n",
    "    \n",
    "    \n",
    "    #置信度是对预测为正例的概率的要求\n",
    "    for i in range(len(result_mon)):\n",
    "        sm_vector = result_mon[i]\n",
    "        predicted_class = np.argmax(sm_vector)\n",
    "        max_prob = max(sm_vector)\n",
    "\n",
    "        if predicted_class in mon_label: # predicted as Monitored\n",
    "            if max_prob >= threshold_val: # predicted as Monitored and actual site is Monitored\n",
    "                TP = TP + 1\n",
    "            else: # predicted as Unmonitored and actual site is Monitored\n",
    "                FN = FN + 1\n",
    "        elif predicted_class in unmon_label: # predicted as Unmonitored and actual site is Monitored\n",
    "            FN = FN + 1\n",
    "\n",
    "    # ==============================================================\n",
    "    # Test with Unmonitored testing instances\n",
    "    # evaluation\n",
    "    for i in range(len(result_unmon)):\n",
    "        sm_vector = result_unmon[i]\n",
    "        predicted_class = np.argmax(sm_vector)\n",
    "        max_prob = max(sm_vector)\n",
    "\n",
    "        if predicted_class in mon_label: # predicted as Monitored\n",
    "            if max_prob >= threshold_val: # predicted as Monitored and actual site is Unmonitored\n",
    "                FP = FP + 1\n",
    "            else: # predicted as Unmonitored and actual site is Unmonitored\n",
    "                TN = TN + 1\n",
    "        elif predicted_class in unmon_label: # predicted as Unmonitored and actual site is Unmonitored\n",
    "            TN = TN + 1\n",
    "\n",
    "    \n",
    "    print (\"TP : \", TP)\n",
    "    print (\"FP : \", FP)\n",
    "    print (\"TN : \", TN)\n",
    "    print (\"FN : \", FN)\n",
    "    print (\"Total  : \", TP + FP + TN + FN)\n",
    "    TPR = float(TP) / (TP + FN)\n",
    "    print (\"TPR : \", TPR)\n",
    "    FPR = float(FP) / (FP + TN)\n",
    "    print (\"FPR : \",  FPR)\n",
    "    Precision = float(TP) / (TP + FP)\n",
    "    print (\"Precision : \", Precision)\n",
    "    Recall = float(TP) / (TP + FN)\n",
    "    print (\"Recall : \", Recall)\n",
    "    log_file.writelines(f\"two-*:\\nthreshold_val: {threshold_val}\\nTP: {TP}, FP: {FP}, TN: {TN}, FN: {FN}\\nTPR:{TPR}, FPR:{FPR}, Precision: {Precision}, Recall:{Recall}\\n\")\n",
    "    \n",
    "    log_file.writelines(f\"test_acc:\\nmon_correct: {mon_correct}  unmon_correct: {unmon_correct}\\nmon_num: {len(mon_label)}   unmon_num: {len(unmon_label)}\\nTest Accuracy: {test_acc}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation type:  OpenWorld_wtfpad\n",
      "置信度:  [0.10874906 0.35328299 0.53072375 0.65947982 0.75290888 0.82070366\n",
      " 0.86989748 0.90559391 0.93149626 0.95029174 0.96393027 0.97382678\n",
      " 0.98100797 0.98621884 0.99      ]\n"
     ]
    }
   ],
   "source": [
    "evaluation_type = 'OpenWorld_wtfpad'\n",
    "print (\"Evaluation type: \", evaluation_type)\n",
    "threshold = 1.0 - 1 / np.logspace(0.05, 2, num=15, endpoint=True)\n",
    "print('置信度: ', threshold)\n",
    "file_name = f'/home/xjj/projects/graduate_project/df_wtf_pad/evaluation/{evaluation_type}_two.txt'\n",
    "log_file =  open(file_name, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading WTFPAD dataset for open-world scenario for evaluation\n",
      "Data loaded!\n",
      "Loading DF model ...\n",
      "The log file will be saved at  /home/xjj/projects/graduate_project/df_wtf_pad/evaluation/OpenWorld_wtfpad_two.txt\n",
      "-- The log file will contains\n",
      "-- TP, FP, TN, FN, TPR, FPR, Precision, and Recall for each different threshold\n",
      "-- These results will be used to plot the ROC or Precision&Recall Graph\n"
     ]
    }
   ],
   "source": [
    "dataset = {}\n",
    "X_test_Mon, y_test_Mon, X_test_Unmon, y_test_Unmon = LoadDataWTFPADOW_Evaluation()\n",
    "\n",
    "dataset['X_test_Mon'] = X_test_Mon\n",
    "dataset['y_test_Mon'] = y_test_Mon\n",
    "dataset['X_test_Unmon'] = X_test_Unmon\n",
    "dataset['y_test_Unmon'] = y_test_Unmon\n",
    "\n",
    "print (\"Data loaded!\")\n",
    "print (\"Loading DF model ...\")\n",
    "print (\"The log file will be saved at \", file_name)\n",
    "print (\"-- The log file will contains\")\n",
    "print (\"-- TP, FP, TN, FN, TPR, FPR, Precision, and Recall for each different threshold\")\n",
    "print (\"-- These results will be used to plot the ROC or Precision&Recall Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(94.) tensor(0.)\n",
      "tensor(95.) tensor(95.)\n"
     ]
    }
   ],
   "source": [
    "print(y_test_Mon.max(), y_test_Mon.min())     #94 0\n",
    "print(y_test_Unmon.max(), y_test_Unmon.min())    #95 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total testing data  29500\n",
      "torch.Size([9500, 96]) torch.Size([20000, 96])\n"
     ]
    }
   ],
   "source": [
    "result_Mon, result_Unmon = predict(dataset, net)\n",
    "print(result_Mon.shape, result_Unmon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP :  9203\n",
      "FP :  5280\n",
      "TN :  14720\n",
      "FN :  297\n",
      "Total  :  29500\n",
      "TPR :  0.9687368421052631\n",
      "FPR :  0.264\n",
      "Precision :  0.6354346475177794\n",
      "Recall :  0.9687368421052631\n",
      "TP :  9071\n",
      "FP :  4879\n",
      "TN :  15121\n",
      "FN :  429\n",
      "Total  :  29500\n",
      "TPR :  0.9548421052631579\n",
      "FPR :  0.24395\n",
      "Precision :  0.6502508960573476\n",
      "Recall :  0.9548421052631579\n",
      "TP :  8769\n",
      "FP :  3801\n",
      "TN :  16199\n",
      "FN :  731\n",
      "Total  :  29500\n",
      "TPR :  0.9230526315789473\n",
      "FPR :  0.19005\n",
      "Precision :  0.6976133651551313\n",
      "Recall :  0.9230526315789473\n",
      "TP :  8499\n",
      "FP :  2897\n",
      "TN :  17103\n",
      "FN :  1001\n",
      "Total  :  29500\n",
      "TPR :  0.8946315789473684\n",
      "FPR :  0.14485\n",
      "Precision :  0.7457879957879958\n",
      "Recall :  0.8946315789473684\n",
      "TP :  8269\n",
      "FP :  2314\n",
      "TN :  17686\n",
      "FN :  1231\n",
      "Total  :  29500\n",
      "TPR :  0.870421052631579\n",
      "FPR :  0.1157\n",
      "Precision :  0.7813474440139847\n",
      "Recall :  0.870421052631579\n",
      "TP :  8101\n",
      "FP :  1901\n",
      "TN :  18099\n",
      "FN :  1399\n",
      "Total  :  29500\n",
      "TPR :  0.8527368421052631\n",
      "FPR :  0.09505\n",
      "Precision :  0.8099380123975205\n",
      "Recall :  0.8527368421052631\n",
      "TP :  7941\n",
      "FP :  1580\n",
      "TN :  18420\n",
      "FN :  1559\n",
      "Total  :  29500\n",
      "TPR :  0.8358947368421052\n",
      "FPR :  0.079\n",
      "Precision :  0.8340510450582922\n",
      "Recall :  0.8358947368421052\n",
      "TP :  7814\n",
      "FP :  1305\n",
      "TN :  18695\n",
      "FN :  1686\n",
      "Total  :  29500\n",
      "TPR :  0.8225263157894737\n",
      "FPR :  0.06525\n",
      "Precision :  0.8568922030924443\n",
      "Recall :  0.8225263157894737\n",
      "TP :  7682\n",
      "FP :  1105\n",
      "TN :  18895\n",
      "FN :  1818\n",
      "Total  :  29500\n",
      "TPR :  0.8086315789473684\n",
      "FPR :  0.05525\n",
      "Precision :  0.8742460452941846\n",
      "Recall :  0.8086315789473684\n",
      "TP :  7540\n",
      "FP :  941\n",
      "TN :  19059\n",
      "FN :  1960\n",
      "Total  :  29500\n",
      "TPR :  0.7936842105263158\n",
      "FPR :  0.04705\n",
      "Precision :  0.8890461030538852\n",
      "Recall :  0.7936842105263158\n",
      "TP :  7413\n",
      "FP :  785\n",
      "TN :  19215\n",
      "FN :  2087\n",
      "Total  :  29500\n",
      "TPR :  0.7803157894736842\n",
      "FPR :  0.03925\n",
      "Precision :  0.9042449377897048\n",
      "Recall :  0.7803157894736842\n",
      "TP :  7291\n",
      "FP :  660\n",
      "TN :  19340\n",
      "FN :  2209\n",
      "Total  :  29500\n",
      "TPR :  0.7674736842105263\n",
      "FPR :  0.033\n",
      "Precision :  0.9169915733869953\n",
      "Recall :  0.7674736842105263\n",
      "TP :  7149\n",
      "FP :  565\n",
      "TN :  19435\n",
      "FN :  2351\n",
      "Total  :  29500\n",
      "TPR :  0.7525263157894737\n",
      "FPR :  0.02825\n",
      "Precision :  0.9267565465387607\n",
      "Recall :  0.7525263157894737\n",
      "TP :  7006\n",
      "FP :  463\n",
      "TN :  19537\n",
      "FN :  2494\n",
      "Total  :  29500\n",
      "TPR :  0.7374736842105263\n",
      "FPR :  0.02315\n",
      "Precision :  0.9380104431650823\n",
      "Recall :  0.7374736842105263\n",
      "TP :  6876\n",
      "FP :  402\n",
      "TN :  19598\n",
      "FN :  2624\n",
      "Total  :  29500\n",
      "TPR :  0.7237894736842105\n",
      "FPR :  0.0201\n",
      "Precision :  0.9447650453421269\n",
      "Recall :  0.7237894736842105\n"
     ]
    }
   ],
   "source": [
    "for th in threshold:\n",
    "    evaluate(th, y_test_Mon, y_test_Unmon, result_Mon, result_Unmon, log_file)\n",
    "log_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
